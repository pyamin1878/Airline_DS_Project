{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Title"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our company is making the venture into the airline industry. We have been tasked with determining which aircraft carry the lowest risk. In this notebook, we have provided three recommendation for our company's airplane purchases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Business Understanding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "stakeholder and business questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Understanding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data source and properties and why relevant to problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data has been provided in this [Aviation Accident Database 1948-2022](https://www.kaggle.com/datasets/khsamaha/aviation-accident-database-synopses) which is publicly available through [kaggle](https://www.kaggle.com/) datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../Final_Data/Aviation_Data.csv', parse_dates=['Event.Date', 'Publication.Date'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "explore properties of data and why it's well suited to solivng the prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe(datetime_is_numeric=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exploring columns that we may want to drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Air.carrier'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Purpose.of.flight'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['FAR.Description'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Schedule'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Report.Status'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "rationalize every step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Making a subset. I.e. dropping columns we don't want from the data understanding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explaining which columns we chose to drop b/c obviously not relevant or redundant: event.id, ivestigation.type, accident.number. latitude, longitude, registration.number, report.status, publication.date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explaining columns which might be relevant to other business questions: airport.code, airport.name, FAR Description, schedule, purpose.of.flight, air.carrier, broad.phase.of.flight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making a Subset by Dropping Columns and Rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_subset = df[['Event.Date', 'Location', 'Country', 'Number.of.Engines',\n",
    "                'Aircraft.damage', 'Aircraft.Category', 'Make', 'Model', \n",
    "                'Amateur.Built', 'Engine.Type',\n",
    "                'Total.Fatal.Injuries', 'Total.Minor.Injuries', \n",
    "                'Total.Uninjured', 'Total.Serious.Injuries', \n",
    "                'Weather.Condition']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardizing the formatting of the column names\n",
    "\n",
    "df_subset = df_subset.rename(columns = lambda x: x.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keeping only airplanes\n",
    "\n",
    "df_subset = df_subset.loc[df_subset['aircraft.category'] == 'Airplane']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping the 'aircraft.category' column\n",
    "\n",
    "df_subset = df_subset.drop(columns=['aircraft.category'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keeping only non-amateur built airplanes\n",
    "\n",
    "df_subset = df_subset.loc[df_subset['amateur.built'] == 'No']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping the 'amateur.built' column\n",
    "\n",
    "df_subset = df_subset.drop(columns=['amateur.built'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keeping only the year (first 4 characters) from the 'event.date' column\n",
    "\n",
    "df_subset = df_subset.rename(columns = lambda x: x.lower())\n",
    "df_subset['event.date'] = pd.to_datetime(df_subset['event.date']).dt.year\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keeping only the state abbreviations from 'location' column into a new column\n",
    "\n",
    "df_subset['state'] = df_subset['location'].str.split(\",\").str[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping the 'location' column\n",
    "\n",
    "df_subset = df_subset.drop(columns=['location'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exploring the 'weather.condition' column\n",
    "\n",
    "df_subset['weather.condtion'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning typos from weather.condition\n",
    "\n",
    "replace_dict = {'Unk':'UNK'}\n",
    "df_subset['weather.condition'] = df_subset['weather.condition'].replace(replace_dict)\n",
    "df_subset['weather.condition'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exploring the 'engine.type' column\n",
    "\n",
    "df_subset['engine.type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning typos from engine.type\n",
    "\n",
    "replace_dict3 = {'UNK':'Unknown'}\n",
    "df_subset['engine.type'] = df_subset['engine.type'].replace(replace_dict3)\n",
    "df_subset['engine.type'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Understanding for our new data set having dropped unecessary info and cleaned redundant values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_subset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_subset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_subset.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_subset.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning Null Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_subset.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping rows in columns that have very few nulls\n",
    "\n",
    "df_subset = df_subset.dropna(subset=['country', 'make', 'model', 'state'])\n",
    "df_subset.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filling the NaN's in the 4 injuries columns with 0's\n",
    "\n",
    "df_subset['total.serious.injuries'].fillna(0, inplace=True)\n",
    "df_subset['total.fatal.injuries'].fillna(0, inplace=True)\n",
    "df_subset['total.minor.injuries'].fillna(0, inplace=True)\n",
    "df_subset['total.uninjured'].fillna(0, inplace=True)\n",
    "\n",
    "df_subset.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replacing nulls in the 'aircraft.damage' column\n",
    "\n",
    "df_subset['aircraft.damage'].value_counts()\n",
    "df_subset['aircraft.damage'] = df_subset['aircraft.damage'].fillna('N/A')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combining 'Unknown' and 'N/A' values in in the 'aircraft.damage' column\n",
    "\n",
    "replace_dict2 = {'Unknown':'N/A'}\n",
    "df_subset['aircraft.damage'] = df_subset['aircraft.damage'].replace(replace_dict2)\n",
    "df_subset['aircraft.damage'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_subset2.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replacing nulls in the 'engine.type' column\n",
    "\n",
    "df_subset['engine.type'].value_counts()\n",
    "df_subset['engine.type'] = df_subset['engine.type'].fillna('Unknown')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_subset.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replacing nulls in the 'weather.condition' column\n",
    "\n",
    "df_subset['weather.condition'].value_counts()\n",
    "df_subset['weather.condition'] = df_subset['weather.condition'].fillna('N/A')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_subset.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, to deal with nulls in the 'number.of.engines' column, we will search for an appropriate measure of central tendency. We cannot fill the nulls with 0's, as this doesn't make conceptual sense: there are no planes with no engines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the distribution of the 'number.of.engines' column\n",
    "\n",
    "df_subset['number.of.engines'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number.engines.hist, ax = plt.subplots\n",
    "ax.hist(number.of.engines, bins = 7)\n",
    "ax.set_xlabel('number.of.engines')\n",
    "ax.set_ylabel('count')\n",
    "ax.set_title('Distribution of number.of.engines')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replacing nulls in the 'number.of.engines' column\n",
    "\n",
    "df_subset['number.of.engines'].median()\n",
    "df_subset['number.of.engines'] = df_subset['number.of.engines'].fillna(df_subset['number.of.engines'].median())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Consolidating the serious injuries and minor injuries columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "why we do this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_subset2['total.nonfatal.injuries'] = df_subset['total.minor.injuries'] + df_subset['total.serious.injuries']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_subset = df_subset.drop(columns=['total.serious.injuries', 'total.minor.injuries'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Typecasting: Changing float columns into integer columns "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why we do this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_subset.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_subset['number.of.engines'] = df_subset['number.of.engines'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_subset['total.serious.injuries'] = df_subset['total.serious.injuries'].astype(int)\n",
    "df_subset['total.fatal.injuries'] = df_subset['total.fatal.injuries'].astype(int)\n",
    "df_subset['total.minor.injuries'] = df_subset['total.minor.injuries'].astype(int)\n",
    "df_subset['total.uninjured'] = df_subset['total.uninjured'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_subset.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating/creating new injuries percentage columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turning injury columns into percentage of total passengers\n",
    "df_subset['fatal.injuries.perc'] = round(((df_subset['total.fatal.injuries'] / (df_subset2['total.fatal.injuries'] + \n",
    "                                                                             df_subset2['total.nonfatal.injuries'] + \n",
    "                                                                             df_subset2['total.uninjured'])) * 100), 1)\n",
    "df_subset['nonfatal.injuries.perc'] = round(((df_subset['total.nonfatal.injuries'] / (df_subset2['total.fatal.injuries'] + \n",
    "                                                                             df_subset2['total.nonfatal.injuries'] + \n",
    "                                                                             df_subset2['total.uninjured'])) * 100), 1)\n",
    "df_subset['uninjured.perc'] = round(((df_subset['total.uninjured'] / (df_subset2['total.fatal.injuries'] + \n",
    "                                                                             df_subset2['total.nonfatal.injuries'] + \n",
    "                                                                             df_subset2['total.uninjured'])) * 100), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning resulting nulls\n",
    "\n",
    "df_subset.isna().sum()\n",
    "\n",
    "df_subset['fatal.injuries.perc'].fillna(0, inplace=True)\n",
    "df_subset['nonfatal.injuries.perc'].fillna(0, inplace=True)\n",
    "df_subset['uninjured.perc'].fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_subset.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turning the new injuries percentage columns into integers\n",
    "\n",
    "df_subset['fatal.injuries.perc'] = df_subset['fatal.injuries.perc'].astype(int)\n",
    "df_subset['nonfatal.injuries.perc'] = df_subset['nonfatal.injuries.perc'].astype(int)\n",
    "df_subset['uninjured.perc'] = df_subset['uninjured.perc'].astype(int)\n",
    "\n",
    "df_subset.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Translating the aircraft damage column into a numerical scale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "why we do this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_subset['aircraft.damage'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aircraft_damage_numbers(y):\n",
    "    if y == \"Substantial\":\n",
    "        return 3\n",
    "    elif y == \"Destroyed\":\n",
    "        return 2\n",
    "    elif y == \"Minor\":\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_subset['aircraft.damage.scale'] = df_subset['aircraft.damage'].map(aircraft_damage_numbers)\n",
    "df_subset['aircraft.damage.scale'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning the 'make' column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_subset['make'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardizing the capitalization of every value\n",
    "\n",
    "df_subset['make'] = df_subset['make'].astype(str).str.lower()\n",
    "pd.set_option('display.max_rows', None)\n",
    "df_subset['make'].value_counts().head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining a function to fix the typos in the most common makes\n",
    "\n",
    "def typos(x):\n",
    "    if \"air tractor\" in x:\n",
    "        return \"air tractor\"\n",
    "    elif \"cessna\" in x:\n",
    "        return \"cessna\"\n",
    "    elif \"piper\" in x:\n",
    "        return \"piper\"\n",
    "    elif \"beech\" in x:\n",
    "        return \"beech\"\n",
    "    elif \"boeing\" in x:\n",
    "        return \"boeing\"\n",
    "    elif \"mooney\" in x:\n",
    "        return \"mooney\"\n",
    "    elif \"grumman\" in x:\n",
    "        return \"grumman\"\n",
    "    elif \"airbus\" in x:\n",
    "        return \"airbus\"\n",
    "    elif \"aeronca\" in x:\n",
    "        return \"aeronca\"\n",
    "    elif \"cirrus\" in x:\n",
    "        return \"cirrus\"\n",
    "    elif \"champion\" in x:\n",
    "        return \"american champion\"\n",
    "    elif \"embraer\" in x:\n",
    "        return \"embraer\"\n",
    "    elif \"havilland\" in x:\n",
    "        return \"dehavilland\"\n",
    "    elif \"aviat\" in x:\n",
    "        return \"aviat\"\n",
    "    elif \"diamond\" in x:\n",
    "        return \"diamond\"\n",
    "    elif \"ercoupe\" in x:\n",
    "        return \"ercoupe\"\n",
    "    else:\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_subset['make'] = df_subset['make'].map(typos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining and saving our cleaned subset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are dropping columns used for calculations of percentages and aircraft damage scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_subset = df_subset[['event.date', 'country', 'state', 'number.of.engines',\n",
    "                'make', 'model', 'engine.type',  \n",
    "                 'fatal.injuries.perc', 'nonfatal.injuries.perc', 'uninjured.perc', \n",
    "                'weather.condition', 'aircraft.damage.scale']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_subset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_subset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_subset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_subset.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_subset.to_csv('../Final_Data/subset.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "why we aren't re-indexing the subset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining a second subset that only contains plane makes (brands) with over 100 entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_value_counts = df_subset['make'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_over_100 = make_value_counts.loc[make_value_counts > 100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_over_100 = list(make_over_100.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_over_100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_subset_makes = df_subset.loc[df_subset['make'].isin(make_over_100)]\n",
    "df_subset_makes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_subset_makes.to_csv('../Final_Data/df_subset_makes.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_subset2_makes.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_subset2_makes.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusion: we now have two data subsets. Explain them"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis and Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the groupby's and the visuals produced in tableau embedded following those cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_subset.groupby('event.date').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_subset.groupby('country').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_subset.groupby('state').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_subset.groupby('number.of.engines').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_subset_makes.groupby('make').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_subset.groupby('engine.type').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_subset.groupby('weather.condition').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_subset.groupby('aircraft.damage.scale').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Business Recommendation 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_subset.groupby('engine.type')['aircraft.damage.scale', 'fatal.injuries.perc'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Business Recommendation 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_subset.groupby('number.of.engines')['aircraft.damage.scale', 'fatal.injuries.perc'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Business Recommendation 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_subset_makes.groupby('make')['aircraft.damage.scale', 'fatal.injuries.perc'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Airbus or Boeing Turbo Fan Planes\n",
    "Chartered flights: single engine planes\n",
    "Commercial flights: dual engine planes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Next Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
